{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:47:39.291361Z",
     "iopub.status.busy": "2025-05-19T07:47:39.290635Z",
     "iopub.status.idle": "2025-05-19T07:47:45.394763Z",
     "shell.execute_reply": "2025-05-19T07:47:45.394124Z",
     "shell.execute_reply.started": "2025-05-19T07:47:39.291331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoc/anaconda3/envs/geochat/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from utils import load_model, load_model_skyclip, load_model_skyclip_2, load_xview_dataset, get_text_features\n",
    "from evaluation import image_level_test\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, id_label_dict, superclass_mapped, dictionary=load_xview_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. RemoteCLIP\n",
    "**a. Download model** (For the first time!)\n",
    "\n",
    "Create a folder for the project and folder for downloading models\n",
    "```\n",
    "!mkdir RS-Foundation-Model\n",
    "!mkdir foundation_models\n",
    "!mkdir foundation_models/remote_sensing\n",
    "!mkdir foundation_models/remote_sensing/RemoteCLIP\n",
    "!mkdir foundation_models/remote_sensing/GeoRSCLIP\n",
    "!mkdir foundation_models/remote_sensing/SkyCLIP\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = hf_hub_download(\"chendelong/RemoteCLIP\", \"RemoteCLIP-ViT-L-14.pt\", cache_dir='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints/models--chendelong--RemoteCLIP/snapshots/bf1d8a3ccf2ddbf7c875705e46373bfe542bce38/RemoteCLIP-ViT-L-14.pt\n"
     ]
    }
   ],
   "source": [
    "!mv checkpoints/ ../foundation_models/remote_sensing/RemoteCLIP/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoc/anaconda3/envs/geochat/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "folder = \"../foundation_models/remote_sensing/RemoteCLIP/\"\n",
    "filename = \"checkpoints/models--chendelong--RemoteCLIP/snapshots/bf1d8a3ccf2ddbf7c875705e46373bfe542bce38/RemoteCLIP-ViT-L-14.pt\"\n",
    "checkpoint_path = os.path.join(folder, filename)\n",
    "model_name = 'ViT-L-14'\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "checkpoint_path = checkpoint_path\n",
    "model, preprocess, tokenizer=load_model(model_name, device, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoc/anaconda3/envs/geochat/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    }
   ],
   "source": [
    "text_features = get_text_features(model, tokenizer, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:16<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_1_accuracy=15.789473684210526, top_5_accuracy=64.91228070175438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.789473684210526, 64.91228070175438)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olabel = 1\n",
    "image_level_test(model, preprocess, text_features, olabel, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. GeoRSCLIP\n",
    "**a. Download model** (For the first time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/Zilun/GeoRSCLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%rm -r GeoRSCLIP/ckpt/RS5M_ViT-B-32*.pt\n",
    "%rm -r GeoRSCLIP/ckpt/RS5M_ViT-L-14-336.pt\n",
    "%mkdir models/GeoRSCLIP\n",
    "%mv /kaggle/working/RS-Foundation-Model/GeoRSCLIP/ckpt/* models/GeoRSCLIP/\n",
    "%rm -r GeoRSCLIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folder = \"../foundation_models/remote_sensing/GeoRSCLIP/\"\n",
    "filename = \"RS5M_ViT-L-14.pt\"\n",
    "checkpoint_path = os.path.join(folder, filename)\n",
    "model_name = 'ViT-L-14'\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "model, preprocess, tokenizer=load_model(model_name, device, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quoc/anaconda3/envs/geochat/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n"
     ]
    }
   ],
   "source": [
    "text_features = get_text_features(model, tokenizer, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:04<00:00, 12.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_1_accuracy=57.89473684210527, top_5_accuracy=94.73684210526315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57.89473684210527, 94.73684210526315)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olabel = 1\n",
    "image_level_test(model, preprocess, text_features, olabel, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. SkyCLIP\n",
    "**a. Download model** (For the first time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"SkyCLIP_ViT_L14_top30pct_filtered_by_CLIP_laion_RS.zip\"\n",
    "!curl -O https://opendatasharing.s3.us-west-2.amazonaws.com/SkyScript/ckpt/{MODEL_NAME}\n",
    "!mv {MODEL_NAME} foundation_models/remote_sensing/SkyCLIP/\n",
    "!unzip foundation_models/remote_sensing/SkyCLIP/SkyCLIP_ViT_L14_top30pct_filtered_by_CLIP_laion_RS.zip -d models/SkyCLIP/\n",
    "!rm foundation_models/remote_sensing/SkyCLIP/SkyCLIP_ViT_L14_top30pct_filtered_by_CLIP_laion_RS.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. Load model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T07:47:48.523884Z",
     "iopub.status.busy": "2025-05-19T07:47:48.522944Z",
     "iopub.status.idle": "2025-05-19T07:47:57.722390Z",
     "shell.execute_reply": "2025-05-19T07:47:57.721358Z",
     "shell.execute_reply.started": "2025-05-19T07:47:48.523845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folder = \"../foundation_models/remote_sensing/SkyCLIP/\"\n",
    "filename = \"SkyCLIP_ViT_L14_top30pct_filtered_by_CLIP_laion_RS/epoch_20.pt\"\n",
    "checkpoint_path = os.path.join(folder, filename)\n",
    "model_name = 'ViT-L-14'\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "src_path_to_skyscript = \"SkyScript\"\n",
    "model, preprocess, tokenizer=load_model_skyclip(model_name, device, checkpoint_path, src_path_to_skyscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = get_text_features(model, tokenizer, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [00:14<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_1_accuracy=22.807017543859647, top_5_accuracy=87.71929824561403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22.807017543859647, 87.71929824561403)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olabel = 1\n",
    "image_level_test(model, preprocess, text_features, olabel, df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1561333,
     "sourceId": 2571636,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "geochat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
